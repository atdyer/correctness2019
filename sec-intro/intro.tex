\section{Introduction}

%Computations on sparse matrices are prevalent in scientific and engineering software.  
Sparse matrix data formats can be used to compress large matrices with a small number of non-zero elements into a more efficient representation.  
%The development of software that makes use of sparse matrices is a tedious and often error-prone task because of the myriad data formats and complexities involved in tuning the operations on these formats to achieve an efficient implementation.
Scientific and engineering software that make use of sparse matrix formats are often implemented in low-level imperative languages such as C++ and Fortran.  The optimized nature of these software often means that the structural organization of sparse matrix formats and mathematical computations are heavily intertwined.  Additionally, the myriad data formats and complexities involved in tuning the operations on these formats to achieve efficient implementations means the development of software that utilizes sparse matrices can be a tedious and error-prone task.

% TODO: list solvers that require sparse input
Often, the solvers provided by popular linear algebra libraries used in scientific computing require assembled sparse matrices as input, leaving the entire assembly process to the developer.  Considering the problem domains in which they are used, this can quickly become a complex task.  For example, sparse matrices are often used to represent the meshes used in the finite element and finite difference methods.  In order to represent physical properites, these meshes can contain rich datasets, the values of which may depend on the complex spatial relationships of the mesh components.  As a result, the matrix assembly process can quickly become intertwined with the mathematics required to determine the precise values that will be placed in the matrix.  Furthermore, as performance improvements are made by, for example, exploiting parallelism in modern hardware, the assembly process and embedded calculations can become even more complex.

To address the difficulties in assembling a sparse matrix, object-oriented libraries such as PETSc~\cite{petsc2019} and Eigen~\cite{eigenweb2010} provide data abstractions targeted towards specific classes of solvers.  These libraries allow developers to assemble sparse matrices without having to address the structural complexities that a sparse matrix format may present.  However, the utility of these libraries may be limited due to solver limitations or other performance restrictions.

Alternatively, compiler support may help with the development and performance tuning of software that makes use of sparse matrices.  Some compilers~\cite{bik1995, bik1996} allow developers to work with dense matrices in code, generating a sparse program at compile time.  Others~\cite{kotlyar1997} allow the user to provide the compiler with an abstract description of a sparse format, from which the compiler can make automatic optimizations in code.

% Alternatively, there is a body of research that takes the approach of designing and building compilers capable of automatically making decisions about sparse matrix formats and operations.  Some compilers~\cite{bik1995, bik1996} allow developers to work with dense matrices in code, generating a sparse matrix program at compile time.  Others~\cite{kotlyar1997} allow the user to provide the compiler with an abstract description of a sparse format, from which the compiler can make automatic optimizations in code that accesses the sparse data.

% Need to add something about how verification of sparse matrix codes is also difficult, and has only really been done by Arnold.  This is one of our major contributions: sparse matrix codes are difficult to verify (see Arnold), and the development of representation invariants for a number of formats can make this easier.  The representation invariants can be directly translated into code, and used during the development and debugging process to verify that operations on matrices never violate the representation invariants (a la Liskov).

% A number of approaches have been taken in order to address these issues.  Object-oriented libraries such as PETSc~\cite{petsc2019} and Eigen~\cite{eigenweb2010} provide data abstractions targeted towards specific classes of solvers.  These libraries provide templates that allow developers to assemble sparse matrices without having to address the structural complexities that a specific format may present.  These matrices can then be used in a variety of solvers, given that the format is supported.

To mitigate the introduction of errors into code during development, techniques such as unit testing and test-driven development are often employed.  These methods aim to reveal bugs by testing the individual components of a piece of software during development.  While useful, these methods are both tedious, requiring test cases to be written manually, and incomplete, meaning they are incapable of checking every scenario or combination of scenarios.

We describe an approach that allows developers to reason about the inherent complexities of sparse matrix formats and operations without limiting implementation choices.  Elements of this approach include declarative modeling and automatic, push-button analysis using the Alloy Analyzer~\cite{jackson2012}, a lightweight bounded model checking tool.  Characteristics of sparse matrix formats and operations are modeled using abstraction based methods~\cite{clarke1994}, including data~\cite{dingel1995} and predicate~\cite{graf1997} abstraction, data and functional refinement~\cite{woodcock1996}, and other techniques, manually, as part of a modeling process.

% We describe an approach that allows developers to reason about the inherent complexities of sparse matrix formats and operations and to determine invariants that can be used to verify implementations.
%Rather than hiding the complexities of sparse matrix formats by providing data abstractions in code or automatic optimizations in compilers, we propose an approach that allows developers to reason about these complexities.  
% Elements of this approach include declarative modeling and automatic, push-button analysis using the Alloy Analyzer~\cite{jackson2012}, a lightweight bounded model checking tool.  Characteristics of sparse matrices, with their numerous representations and ...hard-to-get-right-implementation-details... are approached using abstraction based methods~\cite{clarke1994}, including data abstraction~\cite{dingel1995} and predicate abstraction~\cite{graf1997}, data and functional refinement~\cite{woodcock1996}, and other techniques, manually, as part of a modeling process...

% TODO: ...in its generality and the fact that we can check much more thoroughly than is possible with, e.g. unit testing.
The benefits of this approach lie in its generality.  In contrast to code, Alloy allows for partial descriptions in which details are hidden behind abstractions.  This allows us to, for example, reason about the complexities of building a sparse matrix without the burden of calculating the specific values that matrix will hold.  Furthermore, in being able to freely choose the level of abstraction, we are able to model a wide range of ---, from specific algorithms written in low-level imperative languages to higher level, abstract concepts. 

- partial descriptions
- level of abstraction
- structure and behavior
% The benefits of this approach lie in its generality.  By using Alloy to perform the modeling and analysis, the modeler may choose the programming language that best fits their needs when transitioning from model to implementation.
% Can reason about existing software.
% Can reason about design of new sparse matrix libraries.
% Can reason about compiler design.

The remainder of this paper is organized as follows.  In Section~\ref{sec:litrev} we discuss related work.  In Section~\ref{sec:alloy} we describe certain elements of lightweight formal methods and how they will be applied to our problem domain using Alloy.  In Section~\ref{sec:models} we model three matrix formats, including one abstract matrix and two sparse matrix formats.  In Section~\ref{sec:trans} we model the translation of a sparse matrix from the ELL format to the CSR format, and in Section~\ref{sec:spmv} we model a sparse matrix-vector multiplication algorithm for the CSR format.  Finally, in Section~\ref{sec:conc} we conclude with future directions and closing remarks.